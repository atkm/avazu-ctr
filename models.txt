Current high scores (1604 total entries):
- Model 1+ (site/app/device_id) on 20% of train. 5050s to train. No tuning.
    Private 0.3969011 (987th); Public 0.3990735
- Model 1+ (site/app/device_id) on train_small. 5050s to train. No tuning.
    Private 0.3977059; Public 0.3997966
- xLearn without count features, on 'small'.
    Private 0.3977579, Public 0.3997753
- Model 3 ('both', incl id cols). On 50% of train.csv. Tuned. Tuning time = 9895s.
    Private 0.4111518 (1162th); Public 0.4131281

Model 5:
- click history

Model 4:
- define user
- count features instead of click-rate features
- different models for site rows and app rows.

Model 3 Plus:
- introduce more columns to Model 3

Model 3:
- user-site interaction (site_id, device_ip), (app_id, device_ip)

Model 2:
- add user-category interaction: count per day (site_category, device_ip), (app_category, device_ip)

Model 1 Plus:
- add C14, C17, and C20 to the model.

Model 1 (basemodel):
- C1
- banner_pos
- site_category_vec
- app_category_vec
- device_type
- device_conn_type
- C15
- C16
- C18
- C19
- C21

No idea yet:
- hour
- device_model
- high-cardinality anonymous variables: C14, C17, C20

Not using:
- site_domain, app_domain: correlated with site/app_id (check)
- device_id: correlated with device_ip (check)

Facts:
- train has 40M lines. test has 4M.
- On a 32GB machine, Model 3 exhausts memory at the (one-hot?) encoding step.
- The click rate for train_small.csv is 0.170. 0.175 for the full data set.
- In the test set, site_id and app_id are mutually exclusive.
- Spark handles string categoricals better than sklearn.
    sklearn's LabelEncoder doesn't equal Spark's StringIndexer.
    CategoricalEncoder is coming to sklearn soon (maybe?)

Ideas:
- Does device_id roughly model users?
    It is most likely noisy, since unique users aren't easy to model.
- LogisticRegression, NaiveBayes, RandomForestClassifier, LinearSVC (use decision_function), Gaussian Naive Bayes
- An user is more likely to click if she clicked previously.
    The number of unique (device_ip, id) tuples is similar to that of device_ip's, so use ip's to represent users.
- Ads on a site and those on an app are mutually exclusive.
    Create separate models for the two types of ads.
- To reduce the number of features when encoding a categorical variable, use count, ranking by count, or probability of each category.
    Other ways to deal with the same issue: feature hashing, embedding into a vector space (embedding_column in tf).
    Look into "locally sensitive hashing" algorithms in Spark.
- Feature selection: sklearn's SelectKBest (and its family), L1, tree models.
    Spark doesn't do recursive elimination, but does chi-square test.
- How to find correlated categorical variables?
- Metrics.
    Use log-loss to evaluate. Others: precision, recall, F2, accuracy (ratio of correct).
- How to model "if the user clicked on an ad previously, she is likely to click again"?
    Use of device_ip and device_id.


