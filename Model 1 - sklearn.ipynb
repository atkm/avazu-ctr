{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO: upgrade the model to support sklearn 0.20. Use the new OneHotEncoder, which supports string features, and ColumnTransformer.\n",
    "\n",
    "Logistic regression model using columns 'C1',\n",
    "                 'banner_pos',\n",
    "                 'site_category',\n",
    "                 'app_category',\n",
    "                 'device_type',\n",
    "                 'device_conn_type',\n",
    "                 'C15',\n",
    "                 'C16',\n",
    "                 'C18',\n",
    "                 'C19',\n",
    "                 'C21'.\n",
    "                 \n",
    "### Model Stats\n",
    "- 01m55s to train 'small' for 2 parameters.\n",
    "- 05m22s to train 'small' for 6 parameters.\n",
    "- 07m21s to train 'small' for 10 parameters.\n",
    "- {0.0001: -0.43356715906855536,\n",
    "  0.001: -0.42629521272437554,\n",
    "  0.01: -0.4242657276526611,\n",
    "  0.1: -0.42427721774829286,\n",
    "  1.0: -0.4245292557309675,\n",
    "  10.0: -0.4246627635916426,\n",
    "  100.0: -0.42472018597787536,\n",
    "  1000.0: -0.42473047099609146,\n",
    "  10000.0: -0.4247623788457422}\n",
    "- {0.001: -0.42629521272437554,\n",
    "  0.0021544346900318843: -0.4252131028945746,\n",
    "  0.004641588833612777: -0.42457692978190453,\n",
    "  0.01: -0.4242657276526611,\n",
    "  0.021544346900318832: -0.4241657671706842,\n",
    "  0.046415888336127774: -0.42418784783505004,\n",
    "  0.1: -0.42427721774829286,\n",
    "  0.21544346900318823: -0.4243908104081527,\n",
    "  0.46415888336127775: -0.4244788065512767,\n",
    "  1.0: -0.4245292557309675},\n",
    "  Test score = -0.4251768174185952\n",
    "- Submission trained on train_small:\n",
    "    + Private 0.4168748\n",
    "    + Public 0.4184437\n",
    "- Train on 0.5 of the data:\n",
    "    + Time: 10m10s.\n",
    "    + Used around 20GB of memory.\n",
    "    + Private 0.4172254\n",
    "    + Public 0.4188042"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tools.cv_tools import fit_encoders, neg_log_loss_score, train_test_split\n",
    "\n",
    "import operator\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop cross validation\n",
    "Test set = Day 30. Days 20-29 are partitioned into train and dev sets.\n",
    "\n",
    "| Train | Dev |\n",
    "|:-----:|:----:|\n",
    "| 20-28 | 29 |\n",
    "| 20-27 | 28 |\n",
    "| ...   | ...|\n",
    "| 20-24 | 25 |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# helper functions\n",
    "\n",
    "# this is specific to the model\n",
    "def fit_transform_train(X_train, site_category_encoder, app_category_encoder):\n",
    "    # step 0: apply site_category encoder\n",
    "    X_train.site_category = site_category_encoder.transform(X_train.site_category)\n",
    "    # step 1: apply site_category encoder\n",
    "    X_train.app_category = app_category_encoder.transform(X_train.app_category)\n",
    "    X_train = X_train.values\n",
    "    # step 2: apply one-hot encoding\n",
    "    # when transforming, an unknown categorical feature is mapped to a zero vector\n",
    "    oh_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    X_train = oh_encoder.fit_transform(X_train)\n",
    "    return X_train, oh_encoder\n",
    "\n",
    "# this is specific to the model\n",
    "def transform_dev(X_dev, site_category_encoder, app_category_encoder, oh_encoder):\n",
    "    # step 0\n",
    "    X_dev.site_category = site_category_encoder.transform(X_dev.site_category)\n",
    "    # step 1\n",
    "    X_dev.app_category = app_category_encoder.transform(X_dev.app_category)\n",
    "    X_dev = oh_encoder.transform(X_dev)\n",
    "    return X_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _fit_and_score(X_train, y_train, X_dev, y_dev,\n",
    "                  site_category_encoder, app_category_encoder, param):\n",
    "    # the DataFrame needs the hour column for splitting. Drop the column right before training.\n",
    "    X_train = X_train.drop('hour', axis=1)\n",
    "    X_dev = X_dev.drop('hour', axis=1)\n",
    "    \n",
    "    X_train, oh_encoder = fit_transform_train(X_train, site_category_encoder, app_category_encoder)\n",
    "    lg = LogisticRegression(C=param)\n",
    "    lg.fit(X_train, y_train)\n",
    "    X_dev = transform_dev(X_dev, site_category_encoder, app_category_encoder, oh_encoder)\n",
    "    return neg_log_loss_score(lg, X_dev, y_dev)\n",
    "    \n",
    "def score_one_test_day(X_train, y_train, \n",
    "                       site_category_encoder, app_category_encoder,\n",
    "                       test_day, param):\n",
    "    X_train, y_train, X_dev, y_dev = train_test_split(X_train, y_train, test_day)\n",
    "    return _fit_and_score(X_train, y_train, X_dev, y_dev,\n",
    "                         site_category_encoder, app_category_encoder, param)\n",
    "\n",
    "def score_one_param(X_train, y_train,\n",
    "                    site_category_encoder, app_category_encoder,\n",
    "                    param, test_day_ls):\n",
    "    \n",
    "    scores = []\n",
    "    for test_day in test_day_ls:\n",
    "        scores.append(score_one_test_day(X_train, y_train,\n",
    "                                         site_category_encoder, app_category_encoder,\n",
    "                                         test_day, param))\n",
    "\n",
    "    assert len(scores) == len(test_day_ls)\n",
    "\n",
    "    #print('Scores:', scores)\n",
    "    mean_score = sum(scores)/len(scores)\n",
    "    #print('Mean: ', mean_score)\n",
    "    return mean_score\n",
    "    \n",
    "def score_params(X_train, y_train,\n",
    "                 site_category_encoder, app_category_encoder,\n",
    "                 param_ls, test_day_ls):\n",
    "    \"\"\"\n",
    "    Returns a map: parameter -> mean score.\n",
    "    \"\"\"\n",
    "    \n",
    "    result = dict()\n",
    "    for p in param_ls:\n",
    "        result[p] = score_one_param(X_train, y_train,\n",
    "                                    site_category_encoder, app_category_encoder,\n",
    "                                    p, test_day_ls)\n",
    "    return result\n",
    "\n",
    "def best_param(score_dict):\n",
    "    return max(score_dict.items(), key=operator.itemgetter(1))[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_one(df, params):\n",
    "    \"\"\"\n",
    "    df: pd.DataFrame. An output of pd.read_csv('train.csv') with its hour column formatted.\n",
    "    \"\"\"\n",
    "    model_one_cols = ['C1',\n",
    "                 'banner_pos',\n",
    "                 'site_category',\n",
    "                 'app_category',\n",
    "                 'device_type',\n",
    "                 'device_conn_type',\n",
    "                 'C15',\n",
    "                 'C16',\n",
    "                 'C18',\n",
    "                 'C19',\n",
    "                 'C21']\n",
    "    \n",
    "    encoders = fit_encoders(df, ['site_category', 'app_category'])\n",
    "    site_category_encoder = encoders['site_category']\n",
    "    app_category_encoder = encoders['app_category']\n",
    "    clicks = df.click\n",
    "    # need the hour column for splitting\n",
    "    df = df[model_one_cols + ['hour']]\n",
    "    # Day 30 is for testing\n",
    "    X_train, y_train, X_test, y_test = train_test_split(df, clicks, 30)\n",
    "    test_day_ls = [25,26,27,28,29]\n",
    "    \n",
    "    train_begin = time.time()\n",
    "    scores = score_params(X_train, y_train,\n",
    "                          site_category_encoder, app_category_encoder,\n",
    "                          params, test_day_ls)\n",
    "    train_time = time.time() - train_begin\n",
    "    print(\"Train time: \", train_time)\n",
    "    best_C = best_param(scores)\n",
    "    print(\"Best C: \", best_C)\n",
    "    \n",
    "    # Use the best parameter to evaluate the model on the test set.\n",
    "    test_begin = time.time()\n",
    "    test_score = _fit_and_score(X_train, y_train, X_test, y_test,\n",
    "                               site_category_encoder, app_category_encoder, best_C)\n",
    "    test_time = time.time() - test_begin\n",
    "    print(\"Test time: \", test_time)\n",
    "    \n",
    "    return scores, test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_tiny.csv')\n",
    "df.hour = pd.to_datetime(df.hour, format=\"%y%m%d%H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.001     , 0.00215443, 0.00464159, 0.01      , 0.02154435,\n",
       "       0.04641589, 0.1       , 0.21544347, 0.46415888, 1.        ])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#params = [0.001]\n",
    "#K = 4\n",
    "#params = np.logspace(-K, K, num=K*2+1)\n",
    "params = np.logspace(-3, 0, num=10)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:  1.184729814529419\n",
      "Best C:  0.46415888336127775\n",
      "Test time:  0.016676902770996094\n",
      "CPU times: user 1.21 s, sys: 2.23 ms, total: 1.21 s\n",
      "Wall time: 1.22 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "scores, test_score = eval_model_one(df, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.46415888336127775,\n",
       " {0.001: -0.5112606484015165,\n",
       "  0.0021544346900318843: -0.4688670121876982,\n",
       "  0.004641588833612777: -0.44216972031340884,\n",
       "  0.01: -0.4271120181641944,\n",
       "  0.021544346900318832: -0.4184112774561518,\n",
       "  0.046415888336127774: -0.4131558089535118,\n",
       "  0.1: -0.41001835673647247,\n",
       "  0.21544346900318823: -0.4082597092380721,\n",
       "  0.46415888336127775: -0.40789482838251995,\n",
       "  1.0: -0.41009488890773527},\n",
       " -0.470478664934517)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_C = best_param(scores)\n",
    "best_C, scores, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-9c9a2cba73bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model 1 (baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a map: colName -> index\n",
    "def build_colname_idx(df):\n",
    "    return dict(zip(df.columns, range(len(df.columns))))\n",
    "\n",
    "model1_cols = ['C1',\n",
    "             'banner_pos',\n",
    "             'site_category',\n",
    "             'app_category',\n",
    "             'device_type',\n",
    "             'device_conn_type',\n",
    "             'C15',\n",
    "             'C16',\n",
    "             'C18',\n",
    "             'C19',\n",
    "             'C21']\n",
    "\n",
    "str_cols = ['site_category', 'app_category']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_tiny.csv')\n",
    "df.hour = pd.to_datetime(df.hour, format=\"%y%m%d%H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_encoders(df):\n",
    "    site_category_encoder = LabelEncoder()\n",
    "    site_category_encoder.fit(df.site_category)\n",
    "    app_category_encoder = LabelEncoder()\n",
    "    app_category_encoder.fit(df.app_category)\n",
    "    return site_category_encoder, app_category_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LabelEncoder doesn't handle unknown values, so fit them to the entire dataset.\n",
    "site_category_encoder, app_category_encoder = fit_encoders(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_dev_test_split(df):\n",
    "    last_day = 30\n",
    "    last_day_mask = df.hour.dt.day == last_day\n",
    "    df_test = df[last_day_mask]\n",
    "    df_test = df_test[model1_cols + ['click']]\n",
    "    df_dev, df_test = train_test_split(df_test, test_size=0.5, random_state=23)\n",
    "    df_train = df[~last_day_mask]\n",
    "    df_train = df_train[model1_cols + ['click']]\n",
    "    X_train = df_train.drop('click', axis=1)\n",
    "    y_train = df_train.click\n",
    "    X_dev = df_dev.drop('click', axis=1)\n",
    "    y_dev = df_dev.click\n",
    "    X_test = df_test.drop('click', axis=1)\n",
    "    y_test = df_test.click\n",
    "    return X_train, y_train, X_dev, y_dev, X_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train/dev/test split\n",
    "X_train, y_train, X_dev, y_dev, X_test, y_test = train_dev_test_split(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_transform_train(X_train, site_category_encoder, app_category_encoder):\n",
    "    X_train.site_category = site_category_encoder.transform(X_train.site_category)\n",
    "    X_train.app_category = app_category_encoder.transform(X_train.app_category)\n",
    "    X_train = X_train.values\n",
    "    # when transforming, an unknown categorical feature is mapped to a zero vector\n",
    "    oh_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    X_train = oh_encoder.fit_transform(X_train)\n",
    "    return X_train, oh_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_colname_idx = build_colname_idx(X_train)\n",
    "train_colname_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the train set\n",
    "X_train, oh_encoder = fit_transform_train(X_train, site_category_encoder, app_category_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tune: C. Maybe use class_weight. Try different solvers.\n",
    "# Can be parallelized if multi-class.\n",
    "lg = LogisticRegression()\n",
    "lg.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_dev(X_dev, site_category_encoder, app_category_encoder, oh_encoder):\n",
    "    X_dev.site_category = site_category_encoder.transform(X_dev.site_category)\n",
    "    X_dev.app_category = app_category_encoder.transform(X_dev.app_category)\n",
    "    X_dev = oh_encoder.transform(X_dev)\n",
    "    return X_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare the dev set\n",
    "X_dev = transform_dev(X_dev, site_category_encoder, app_category_encoder, oh_encoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lg.score(X_dev, y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
