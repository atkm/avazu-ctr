{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "\n",
    "from tools.cv_tools import (\n",
    "    fit_and_score, neg_log_loss_score,\n",
    "    train_test_split, score_one_param, score_one_test_day,\n",
    "    score_one_param, score_params, best_param\n",
    ")\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get stats\n",
    "- 'both' on 50%:\n",
    "        Private 0.4111518 (1162th); Public 0.4131281\n",
    "\n",
    "        Tuning time:  9895.018527507782\n",
    "        Best C:  {'logistic_regression__C': 1.9306977288832496e-05}\n",
    "        {1e-05: -0.4224259270214176, 1.9306977288832496e-05: -0.4208304486561515, 3.727593720314938e-05: -0.4217097630340418, 7.196856730011514e-05: -0.4247162512096456, 0.00013894954943731373: -0.4291760863913517, 0.00026826957952797245: -0.43419233319954553, 0.0005179474679231213: -0.43884428513031326, 0.001: -0.4425155070224663}\n",
    "        Test score:  -0.4199406310504107\n",
    "- 'both' on mid (10%):\n",
    "        Train time:  1078.5528402328491\n",
    "        {'logistic_regression__C': 7.196856730011514e-05},\n",
    "            {1e-05: -0.43486416112736803,\n",
    "            1.9306977288832496e-05: -0.42865810789142617,\n",
    "            3.727593720314938e-05: -0.42415665503160155,\n",
    "            7.196856730011514e-05: -0.4220119611241461,\n",
    "            0.00013894954943731373: -0.4224520487674228,\n",
    "            0.00026826957952797245: -0.4253182420463687,\n",
    "            0.0005179474679231213: -0.43024372965093827,\n",
    "            0.001: -0.43664129249309813},\n",
    "            -0.42239338987263836\n",
    "- 'both' on small (2.5%):\n",
    "        Private score: 0.4123864 (1178th); Public 0.4142476\n",
    "        \n",
    "        Train time:  235.1989951133728 for 8 parameters\n",
    "        {'logistic_regression__C': 0.00026826957952797245},\n",
    "         {1e-05: -0.45157329102889265,\n",
    "          1.9306977288832496e-05: -0.4427007303707594,\n",
    "          3.727593720314938e-05: -0.4352654288116506,\n",
    "          7.196856730011514e-05: -0.42906363703874895,\n",
    "          0.00013894954943731373: -0.4246260851551441,\n",
    "          0.00026826957952797245: -0.4226054421117388,\n",
    "          0.0005179474679231213: -0.42321956497464086,\n",
    "          0.001: -0.42634305732673894},\n",
    "         -0.41905488258751256\n",
    "- 'user-site' on small (slightly better than 'both'):\n",
    "        {'logistic_regression__C': 0.0005179474679231213},\n",
    "         {1e-05: -0.4519688499795095,\n",
    "          1.9306977288832496e-05: -0.4433754893213299,\n",
    "          3.727593720314938e-05: -0.43615234190368524,\n",
    "          7.196856730011514e-05: -0.4298023929125085,\n",
    "          0.00013894954943731373: -0.4244771101575616,\n",
    "          0.00026826957952797245: -0.420876018386614,\n",
    "          0.0005179474679231213: -0.4196717499105797,\n",
    "          0.001: -0.42093989821434175},\n",
    "         -0.4180792146119277\n",
    "- 'user-app' on small (about the same as 'both'):\n",
    "        {'logistic_regression__C': 0.00026826957952797245},\n",
    "         {1e-05: -0.45157329102889265,\n",
    "          1.9306977288832496e-05: -0.4427007303707594,\n",
    "          3.727593720314938e-05: -0.4352654288116506,\n",
    "          7.196856730011514e-05: -0.42906363703874895,\n",
    "          0.00013894954943731373: -0.4246260851551441,\n",
    "          0.00026826957952797245: -0.4226054421117388,\n",
    "          0.0005179474679231213: -0.42321956497464086,\n",
    "          0.001: -0.42634305732673894},\n",
    "         -0.41905488258751256\n",
    "- 'both' without site/app_id on small (worse than with the id cols):\n",
    "        {'logistic_regression__C': 0.00026826957952797245},\n",
    "         {1e-05: -0.45416005751851846,\n",
    "          1.9306977288832496e-05: -0.4455526673441733,\n",
    "          3.727593720314938e-05: -0.4381691637960564,\n",
    "          7.196856730011514e-05: -0.4317755399506975,\n",
    "          0.00013894954943731373: -0.4270948231851417,\n",
    "          0.00026826957952797245: -0.4249472014637636,\n",
    "          0.0005179474679231213: -0.4256511483857503,\n",
    "          0.001: -0.42909917307589296},\n",
    "         -0.42207645174265146"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ClickRateBySiteEncoder(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    user_site_interaction_cols = ['site_id', 'device_id']\n",
    "    user_app_interaction_cols = ['app_id', 'device_id']\n",
    "    \n",
    "    def __init__(self, interaction='both'):\n",
    "        \"\"\"\n",
    "        interaction can be 'user-site', 'user-app', or 'both' (default).\n",
    "        \"\"\"\n",
    "        assert interaction in ['user-app','user-site','both']\n",
    "        self.interaction = interaction\n",
    "        self.click_rates_by_site_id = None\n",
    "        self.click_rates_by_app_id = None\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\"\n",
    "        X must have the following columns: 'click', 'site_id', 'app_id', and 'device_id'.\n",
    "        Returns a transformed DataFrame with 'click_rate_site_id' and 'click_rate_app_id'.\n",
    "        The 'click' column is dropped.\n",
    "        \"\"\"\n",
    "        if self.interaction != 'app-site':\n",
    "            self.click_rates_by_site_id = X.groupby(ClickRateBySiteEncoder.user_site_interaction_cols)\\\n",
    "                .agg({'click': 'mean'}).rename({'click': 'click_rate_site'}, axis=1)\n",
    "        \n",
    "        if self.interaction != 'user-site':\n",
    "            self.click_rates_by_app_id = X.groupby(ClickRateBySiteEncoder.user_app_interaction_cols)\\\n",
    "                .agg({'click': 'mean'}).rename({'click': 'click_rate_app'}, axis=1)\n",
    "    \n",
    "        return self\n",
    "    \n",
    "    def transform(self, X):\n",
    "        # TODO: need to deal with nulls that appear on rows without matching (device_id, site/app_id) rows.\n",
    "        if self.interaction != 'app-site':\n",
    "            X = pd.merge(X, self.click_rates_by_site_id, how='left',\n",
    "                      on=ClickRateBySiteEncoder.user_site_interaction_cols)\n",
    "            X = X.fillna({'click_rate_site': 0})\n",
    "            \n",
    "        if self.interaction != 'user-site':\n",
    "            X = pd.merge(X, self.click_rates_by_app_id, how='left',\n",
    "                      on=ClickRateBySiteEncoder.user_app_interaction_cols)\n",
    "            X = X.fillna({'click_rate_app': 0})\n",
    "        \n",
    "        # test sets don't have a click column\n",
    "        if 'click' in X.columns:\n",
    "            X = X.drop('click', axis=1)\n",
    "            \n",
    "        return X.drop(['device_id','site_id','app_id'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_three(df, params):\n",
    "    model_three_cols = ['C1',\n",
    "                  'click',\n",
    "                 'banner_pos',\n",
    "                  'app_id',\n",
    "                  'site_id',\n",
    "                  'device_id',\n",
    "                 'device_type',\n",
    "                 'device_conn_type',\n",
    "                 'C15',\n",
    "                 'C16',\n",
    "                 'C18',\n",
    "                 'C19',\n",
    "                 'C21']\n",
    "    \n",
    "    # all except click_rate are categorical features\n",
    "    categorical_features = ['C1',\n",
    "                  'banner_pos',\n",
    "                  'app_id',\n",
    "                  'site_id',\n",
    "                 'device_type',\n",
    "                 'device_conn_type',\n",
    "                 'C15',\n",
    "                 'C16',\n",
    "                 'C18',\n",
    "                 'C19',\n",
    "                 'C21']\n",
    "    \n",
    "    click_rate_cols = ['click', 'app_id',\n",
    "                  'site_id',\n",
    "                  'device_id']\n",
    "    \n",
    "    clicks = df.click\n",
    "    df = df[model_three_cols + ['hour']]\n",
    "    X_train, y_train, X_test, y_test = train_test_split(df, clicks, 30)\n",
    "    test_day_ls = [25,26,27,28,29]\n",
    "    \n",
    "    cr_site_encoder = ClickRateEncoder(['site_id','device_id'], 'click_rate_by_site_id')\n",
    "    cr_app_encoder = ClickRateEncoder(['app_id','device_id'], 'click_rate_by_app_id')\n",
    "    oh_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('one_hot_encoding', oh_encoder, categorical_features),\n",
    "        ('click_rate_encoding_site', cr_site_encoder, ['click','site_id','device_id']),\n",
    "        ('click_rate_encoding_app', cr_app_encoder, ['click','app_id','device_id'])\n",
    "    ])\n",
    "\n",
    "    lg = LogisticRegression(solver='liblinear')\n",
    "    pipeline = Pipeline([\n",
    "                    ('preprocessing', preprocessor),\n",
    "                     ('logistic_regression', lg)])\n",
    "    \n",
    "    C_kwd = 'logistic_regression__C'\n",
    "    params_dict_ls = [{C_kwd: p} for p in params]\n",
    "    \n",
    "    train_begin = time.time()\n",
    "    scores = score_params(X_train, y_train, pipeline, params_dict_ls, test_day_ls)\n",
    "    train_time = time.time() - train_begin\n",
    "    print(\"Train time: \", train_time)\n",
    "    best_C = best_param(scores, params_dict_ls)\n",
    "    print(\"Best C: \", best_C)\n",
    "    \n",
    "    # Use the best parameter to evaluate the model on the test set.\n",
    "    test_begin = time.time()\n",
    "    test_score = fit_and_score(X_train, y_train, X_test, y_test, pipeline, best_C)\n",
    "    test_time = time.time() - test_begin\n",
    "    print(\"Test time: \", test_time)\n",
    "    \n",
    "    return params_dict_ls, scores, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-05, 1.93069773e-05, 3.72759372e-05, 7.19685673e-05,\n",
       "       1.38949549e-04, 2.68269580e-04, 5.17947468e-04, 1.00000000e-03])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train_small.csv')\n",
    "df.hour = pd.to_datetime(df.hour, format=\"%y%m%d%H\")\n",
    "params = np.logspace(-5, -3, num=8)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:  236.44029760360718\n",
      "Best C:  {'logistic_regression__C': 0.00026826957952797245}\n",
      "Test time:  9.750065565109253\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'logistic_regression__C': 0.00026826957952797245},\n",
       " {1e-05: -0.45157329102889265,\n",
       "  1.9306977288832496e-05: -0.4427007303707594,\n",
       "  3.727593720314938e-05: -0.4352654288116506,\n",
       "  7.196856730011514e-05: -0.42906363703874895,\n",
       "  0.00013894954943731373: -0.4246260851551441,\n",
       "  0.00026826957952797245: -0.4226054421117388,\n",
       "  0.0005179474679231213: -0.42321956497464086,\n",
       "  0.001: -0.42634305732673894},\n",
       " -0.41905488258751256)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_dict_ls, scores, test_score = eval_model_three(df, params)\n",
    "best_C = best_param(scores, params_dict_ls)\n",
    "best_C, dict(zip(params, scores)), test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ClickRateEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.base import ClickRateEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_three(df, params):\n",
    "    model_three_cols = ['C1',\n",
    "                  'click',\n",
    "                 'banner_pos',\n",
    "                  'app_id',\n",
    "                  'site_id',\n",
    "                  'device_id',\n",
    "                 'device_type',\n",
    "                 'device_conn_type',\n",
    "                 'C15',\n",
    "                 'C16',\n",
    "                 'C18',\n",
    "                 'C19',\n",
    "                 'C21']\n",
    "    \n",
    "    # all except click_rate are categorical features\n",
    "    categorical_features = ['C1',\n",
    "                  'banner_pos',\n",
    "                  'app_id',\n",
    "                  'site_id',\n",
    "                 'device_type',\n",
    "                 'device_conn_type',\n",
    "                 'C15',\n",
    "                 'C16',\n",
    "                 'C18',\n",
    "                 'C19',\n",
    "                 'C21']\n",
    "    \n",
    "    click_rate_cols = ['click', 'app_id',\n",
    "                  'site_id',\n",
    "                  'device_id']\n",
    "    \n",
    "    clicks = df.click\n",
    "    df = df[model_three_cols + ['hour']]\n",
    "    X_train, y_train, X_test, y_test = train_test_split(df, clicks, 30)\n",
    "    test_day_ls = [25,26,27,28,29]\n",
    "    \n",
    "    cr_site_encoder = ClickRateEncoder(['site_id','device_id'], 'click_rate_by_site_id')\n",
    "    cr_app_encoder = ClickRateEncoder(['app_id','device_id'], 'click_rate_by_app_id')\n",
    "    oh_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('one_hot_encoding', oh_encoder, categorical_features),\n",
    "        ('click_rate_encoding_site', cr_site_encoder, ['click','site_id','device_id']),\n",
    "        ('click_rate_encoding_app', cr_app_encoder, ['click','app_id','device_id'])\n",
    "    ])\n",
    "\n",
    "    lg = LogisticRegression(solver='liblinear')\n",
    "    pipeline = Pipeline([\n",
    "                    ('preprocessing', preprocessor),\n",
    "                     ('logistic_regression', lg)])\n",
    "    \n",
    "    C_kwd = 'logistic_regression__C'\n",
    "    params_dict_ls = [{C_kwd: p} for p in params]\n",
    "    \n",
    "    train_begin = time.time()\n",
    "    scores = score_params(X_train, y_train, pipeline, params_dict_ls, test_day_ls)\n",
    "    train_time = time.time() - train_begin\n",
    "    print(\"Train time: \", train_time)\n",
    "    best_C = best_param(scores, params_dict_ls)\n",
    "    print(\"Best C: \", best_C)\n",
    "    \n",
    "    # Use the best parameter to evaluate the model on the test set.\n",
    "    test_begin = time.time()\n",
    "    test_score = fit_and_score(X_train, y_train, X_test, y_test, pipeline, best_C)\n",
    "    test_time = time.time() - test_begin\n",
    "    print(\"Test time: \", test_time)\n",
    "    \n",
    "    return params_dict_ls, scores, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train time:  239.5106909275055\n",
      "Best C:  {'logistic_regression__C': 0.00026826957952797245}\n",
      "Test time:  9.722646474838257\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'logistic_regression__C': 0.00026826957952797245},\n",
       " {1e-05: -0.45157329102889265,\n",
       "  1.9306977288832496e-05: -0.4427007303707594,\n",
       "  3.727593720314938e-05: -0.4352654288116506,\n",
       "  7.196856730011514e-05: -0.42906363703874895,\n",
       "  0.00013894954943731373: -0.4246260851551441,\n",
       "  0.00026826957952797245: -0.4226054421117388,\n",
       "  0.0005179474679231213: -0.42321956497464086,\n",
       "  0.001: -0.42634305732673894},\n",
       " -0.41905488258751256)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('data/train_small.csv')\n",
    "df.hour = pd.to_datetime(df.hour, format=\"%y%m%d%H\")\n",
    "params = np.logspace(-5, -3, num=8)\n",
    "params_dict_ls, scores, test_score = eval_model_three(df, params)\n",
    "best_C = best_param(scores, params_dict_ls)\n",
    "best_C, dict(zip(params, scores)), test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
