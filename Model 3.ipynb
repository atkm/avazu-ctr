{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from models.model_three import ClickRateBySiteEncoder, tune_model_three, get_model_three_pipeline\n",
    "from models.base import tune_logistic_regression_pipeline\n",
    "\n",
    "from tools.cv_tools import (\n",
    "    fit_and_score, neg_log_loss_score,\n",
    "    train_test_split, score_one_param, score_one_test_day,\n",
    "    score_one_param, score_params, best_param\n",
    ")\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize features\n",
    "Setting mean = 0, stddev = 1 would break sparsity. Just do stddev = 1.\n",
    "\n",
    "- 'both' on small: shows some improvement over the non-standardized model.\n",
    "        Tuning time:  267.5878794193268\n",
    "        {'logistic_regression__C': 1.3894954943731361e-05},\n",
    "        {1e-06: -0.44103828048443294,\n",
    "        1.9306977288832498e-06: -0.4302102379517666,\n",
    "        3.727593720314938e-06: -0.4222077887874803,\n",
    "        7.196856730011514e-06: -0.4177093412638249,\n",
    "        1.3894954943731361e-05: -0.4170384850937549,\n",
    "        2.6826957952797274e-05: -0.4198264908550959,\n",
    "        5.1794746792312125e-05: -0.42536875085310255,\n",
    "        0.0001: -0.4329831633998218},\n",
    "        -0.4131179379019657"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_small.csv')\n",
    "df.hour = pd.to_datetime(df.hour, format=\"%y%m%d%H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = get_model_three_pipeline()\n",
    "lg_step = pipeline.steps.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('preprocessing',\n",
       "  ColumnTransformer(n_jobs=None, remainder='drop', sparse_threshold=0.3,\n",
       "           transformer_weights=None,\n",
       "           transformers=[('one_hot_encoding', OneHotEncoder(categorical_features=None, categories=None,\n",
       "         dtype=<class 'numpy.float64'>, handle_unknown='ignore',\n",
       "         n_values=None, sparse=True), ['C1', 'banner_pos', 'app_id', 'site_id', 'device_type', 'device_conn_type', 'C15', 'C16', 'C18', 'C19', 'C2...e='click_rate_by_app_id',\n",
       "           cols=['app_id', 'device_id']), ['click', 'app_id', 'device_id'])])),\n",
       " ['standardize', StandardScaler(copy=False, with_mean=False, with_std=True)],\n",
       " ('logistic_regression',\n",
       "  LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "            intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "            n_jobs=None, penalty='l2', random_state=None, solver='liblinear',\n",
       "            tol=0.0001, verbose=0, warm_start=False))]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler(copy=False, with_mean=False)\n",
    "pipeline.steps.append(['standardize', scaler])\n",
    "pipeline.steps.append(lg_step)\n",
    "pipeline.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.00000000e-06, 1.93069773e-06, 3.72759372e-06, 7.19685673e-06,\n",
       "       1.38949549e-05, 2.68269580e-05, 5.17947468e-05, 1.00000000e-04])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = np.logspace(-6, -4, num=8)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tuning time:  267.5878794193268\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "({'logistic_regression__C': 1.3894954943731361e-05},\n",
       " {1e-06: -0.44103828048443294,\n",
       "  1.9306977288832498e-06: -0.4302102379517666,\n",
       "  3.727593720314938e-06: -0.4222077887874803,\n",
       "  7.196856730011514e-06: -0.4177093412638249,\n",
       "  1.3894954943731361e-05: -0.4170384850937549,\n",
       "  2.6826957952797274e-05: -0.4198264908550959,\n",
       "  5.1794746792312125e-05: -0.42536875085310255,\n",
       "  0.0001: -0.4329831633998218},\n",
       " -0.4131179379019657)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_C, params_dict_ls, scores, test_score = tune_logistic_regression_pipeline(df, pipeline, params)\n",
    "best_C, dict(zip(params, scores)), test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "No active exception to reraise",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-9c9a2cba73bf>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m: No active exception to reraise"
     ]
    }
   ],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study categorical features vs click rates\n",
    "Question: Is the scale of click rates harming the model, which employs regularization?\n",
    "\n",
    "Result:\n",
    "- most categorical features are very sparse.\n",
    "    The median of means of columns is 1e-6.\n",
    "- some categorical features aren't so sparse.\n",
    "    sum(avg > 0.5), sum(avg > 0.25), sum(avg > 0.1), sum(avg > 0.01) = (7, 12, 20, 72)\n",
    "- the means of click rates are in the > 99.5% percentiles.\n",
    "\n",
    "Answer: since the values of click rates are relatively large, their coefficients should be small.\n",
    "    It is the categorical features that are sparse that "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_small.csv')\n",
    "df.hour = pd.to_datetime(df.hour, format=\"%y%m%d%H\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = get_model_three_pipeline()\n",
    "pipeline.steps.pop()\n",
    "#pipeline.set_params(**{'preprocessing__sparse_threshold': 0})\n",
    "pipeline.steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pipeline.fit_transform(df)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the last two columns are the click rates\n",
    "X[:5, -4:].todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg = np.asarray(X.mean(axis=0))[0] # when the output is a matrix\n",
    "#avg = X.mean(axis=0)\n",
    "avg.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = np.std(X, axis=0)\n",
    "std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# click rate avg\n",
    "avg[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "pd.Series(avg).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(avg > 0.5), sum(avg > 0.25), sum(avg > 0.1), sum(avg > 0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.quantile(avg, 0.997)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(len(avg)),avg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without regularization\n",
    "... Logistic Regression doesn't allow no regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline = get_model_three_pipeline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_C, params_dict_ls, scores, test_score = tune_logistic_regression_pipeline(df, pipeline, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get stats\n",
    "- 'both' on 50%:\n",
    "        Private 0.4111518 (1162th); Public 0.4131281\n",
    "\n",
    "        Tuning time:  9895.018527507782\n",
    "        Best C:  {'logistic_regression__C': 1.9306977288832496e-05}\n",
    "        {1e-05: -0.4224259270214176, 1.9306977288832496e-05: -0.4208304486561515, 3.727593720314938e-05: -0.4217097630340418, 7.196856730011514e-05: -0.4247162512096456, 0.00013894954943731373: -0.4291760863913517, 0.00026826957952797245: -0.43419233319954553, 0.0005179474679231213: -0.43884428513031326, 0.001: -0.4425155070224663}\n",
    "        Test score:  -0.4199406310504107\n",
    "- 'both' on mid (10%):\n",
    "        Train time:  1078.5528402328491\n",
    "        {'logistic_regression__C': 7.196856730011514e-05},\n",
    "            {1e-05: -0.43486416112736803,\n",
    "            1.9306977288832496e-05: -0.42865810789142617,\n",
    "            3.727593720314938e-05: -0.42415665503160155,\n",
    "            7.196856730011514e-05: -0.4220119611241461,\n",
    "            0.00013894954943731373: -0.4224520487674228,\n",
    "            0.00026826957952797245: -0.4253182420463687,\n",
    "            0.0005179474679231213: -0.43024372965093827,\n",
    "            0.001: -0.43664129249309813},\n",
    "            -0.42239338987263836\n",
    "- 'both' on small (2.5%):\n",
    "        Private score: 0.4123864 (1178th); Public 0.4142476\n",
    "        \n",
    "        Train time:  235.1989951133728 for 8 parameters\n",
    "        {'logistic_regression__C': 0.00026826957952797245},\n",
    "         {1e-05: -0.45157329102889265,\n",
    "          1.9306977288832496e-05: -0.4427007303707594,\n",
    "          3.727593720314938e-05: -0.4352654288116506,\n",
    "          7.196856730011514e-05: -0.42906363703874895,\n",
    "          0.00013894954943731373: -0.4246260851551441,\n",
    "          0.00026826957952797245: -0.4226054421117388,\n",
    "          0.0005179474679231213: -0.42321956497464086,\n",
    "          0.001: -0.42634305732673894},\n",
    "         -0.41905488258751256\n",
    "- 'user-site' on small (slightly better than 'both'):\n",
    "        {'logistic_regression__C': 0.0005179474679231213},\n",
    "         {1e-05: -0.4519688499795095,\n",
    "          1.9306977288832496e-05: -0.4433754893213299,\n",
    "          3.727593720314938e-05: -0.43615234190368524,\n",
    "          7.196856730011514e-05: -0.4298023929125085,\n",
    "          0.00013894954943731373: -0.4244771101575616,\n",
    "          0.00026826957952797245: -0.420876018386614,\n",
    "          0.0005179474679231213: -0.4196717499105797,\n",
    "          0.001: -0.42093989821434175},\n",
    "         -0.4180792146119277\n",
    "- 'user-app' on small (about the same as 'both'):\n",
    "        {'logistic_regression__C': 0.00026826957952797245},\n",
    "         {1e-05: -0.45157329102889265,\n",
    "          1.9306977288832496e-05: -0.4427007303707594,\n",
    "          3.727593720314938e-05: -0.4352654288116506,\n",
    "          7.196856730011514e-05: -0.42906363703874895,\n",
    "          0.00013894954943731373: -0.4246260851551441,\n",
    "          0.00026826957952797245: -0.4226054421117388,\n",
    "          0.0005179474679231213: -0.42321956497464086,\n",
    "          0.001: -0.42634305732673894},\n",
    "         -0.41905488258751256\n",
    "- 'both' without site/app_id on small (worse than with the id cols):\n",
    "        {'logistic_regression__C': 0.00026826957952797245},\n",
    "         {1e-05: -0.45416005751851846,\n",
    "          1.9306977288832496e-05: -0.4455526673441733,\n",
    "          3.727593720314938e-05: -0.4381691637960564,\n",
    "          7.196856730011514e-05: -0.4317755399506975,\n",
    "          0.00013894954943731373: -0.4270948231851417,\n",
    "          0.00026826957952797245: -0.4249472014637636,\n",
    "          0.0005179474679231213: -0.4256511483857503,\n",
    "          0.001: -0.42909917307589296},\n",
    "         -0.42207645174265146"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_small.csv')\n",
    "df.hour = pd.to_datetime(df.hour, format=\"%y%m%d%H\")\n",
    "params = np.logspace(-5, -3, num=8)\n",
    "params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "best_C, params_dict_ls, scores, test_score = tune_model_three(df, params)\n",
    "best_C, dict(zip(params, scores)), test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test tune_logistic_regression_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test ClickRateEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from models.base import ClickRateEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model_three(df, params):\n",
    "    model_three_cols = ['C1',\n",
    "                  'click',\n",
    "                 'banner_pos',\n",
    "                  'app_id',\n",
    "                  'site_id',\n",
    "                  'device_id',\n",
    "                 'device_type',\n",
    "                 'device_conn_type',\n",
    "                 'C15',\n",
    "                 'C16',\n",
    "                 'C18',\n",
    "                 'C19',\n",
    "                 'C21']\n",
    "    \n",
    "    # all except click_rate are categorical features\n",
    "    categorical_features = ['C1',\n",
    "                  'banner_pos',\n",
    "                  'app_id',\n",
    "                  'site_id',\n",
    "                 'device_type',\n",
    "                 'device_conn_type',\n",
    "                 'C15',\n",
    "                 'C16',\n",
    "                 'C18',\n",
    "                 'C19',\n",
    "                 'C21']\n",
    "    \n",
    "    click_rate_cols = ['click', 'app_id',\n",
    "                  'site_id',\n",
    "                  'device_id']\n",
    "    \n",
    "    clicks = df.click\n",
    "    df = df[model_three_cols + ['hour']]\n",
    "    X_train, y_train, X_test, y_test = train_test_split(df, clicks, 30)\n",
    "    test_day_ls = [25,26,27,28,29]\n",
    "    \n",
    "    cr_site_encoder = ClickRateEncoder(['site_id','device_id'], 'click_rate_by_site_id')\n",
    "    cr_app_encoder = ClickRateEncoder(['app_id','device_id'], 'click_rate_by_app_id')\n",
    "    oh_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "    preprocessor = ColumnTransformer([\n",
    "        ('one_hot_encoding', oh_encoder, categorical_features),\n",
    "        ('click_rate_encoding_site', cr_site_encoder, ['click','site_id','device_id']),\n",
    "        ('click_rate_encoding_app', cr_app_encoder, ['click','app_id','device_id'])\n",
    "    ])\n",
    "\n",
    "    lg = LogisticRegression(solver='liblinear')\n",
    "    pipeline = Pipeline([\n",
    "                    ('preprocessing', preprocessor),\n",
    "                     ('logistic_regression', lg)])\n",
    "    \n",
    "    C_kwd = 'logistic_regression__C'\n",
    "    params_dict_ls = [{C_kwd: p} for p in params]\n",
    "    \n",
    "    train_begin = time.time()\n",
    "    scores = score_params(X_train, y_train, pipeline, params_dict_ls, test_day_ls)\n",
    "    train_time = time.time() - train_begin\n",
    "    print(\"Train time: \", train_time)\n",
    "    best_C = best_param(scores, params_dict_ls)\n",
    "    print(\"Best C: \", best_C)\n",
    "    \n",
    "    # Use the best parameter to evaluate the model on the test set.\n",
    "    test_begin = time.time()\n",
    "    test_score = fit_and_score(X_train, y_train, X_test, y_test, pipeline, best_C)\n",
    "    test_time = time.time() - test_begin\n",
    "    print(\"Test time: \", test_time)\n",
    "    \n",
    "    return params_dict_ls, scores, test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('data/train_small.csv')\n",
    "df.hour = pd.to_datetime(df.hour, format=\"%y%m%d%H\")\n",
    "params = np.logspace(-5, -3, num=8)\n",
    "params_dict_ls, scores, test_score = eval_model_three(df, params)\n",
    "best_C = best_param(scores, params_dict_ls)\n",
    "best_C, dict(zip(params, scores)), test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Develop test_model_three_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from models.model_three import categorical_features\n",
    "df = pd.read_csv('data/train_tiny.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nuniques(df):\n",
    "    unique_vals = dict()\n",
    "    for c in df:\n",
    "        unique_vals[c] = df[c].nunique()\n",
    "    return unique_vals\n",
    "\n",
    "nuniques = get_nuniques(df[categorical_features])\n",
    "sum(nuniques.values())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
