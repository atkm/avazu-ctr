{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "['id','click','hour','banner_pos','device_id','device_ip','device_model','device_conn_type','C14','C17','C20','C21'], and add cols ['pub_id','pub_domain','pub_category','device_id_count','device_ip_count','user_count','smooth_user_hour_count','user_click_histroy'].\n",
    "\n",
    "Stats:\n",
    "- 'small' with device_* cols: Private=0.3998675, Public=0.4020308\n",
    "- 'small' without device_* cols: Private=0.4024273, Public=0.4045937\n",
    "\n",
    "\n",
    "TODO:\n",
    "- encoding by bucketed click-through rate\n",
    "- throw in other anonymous features like in Model 3+."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xlearn as xl\n",
    "\n",
    "from tools.ffm_tools import make_train_validate_data, df_to_ffm, write_submission\n",
    "from models.base import create_user, site_app_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "\n",
    "def xlearn_train_command(train_set, validation_set, model_type='2', learning_rate=None, reg_param=None):\n",
    "    xlearn_train = '~/code/xlearn/build/xlearn_train'\n",
    "    command = [xlearn_train, train_set,\n",
    "          '-s', str(model_type),\n",
    "         '-v', validation_set]\n",
    "    if learning_rate:\n",
    "        command.append('-r')\n",
    "        command.append(str(learning_rate))                      \n",
    "    if reg_param:\n",
    "        command.append('-b')\n",
    "        command.append('{0:.7f}'.format(reg_param))\n",
    "    return ' '.join(command)\n",
    "\n",
    "def xlearn_predict_command(test_set, model):\n",
    "    xlearn_predict = '~/code/xlearn/build/xlearn_predict'\n",
    "    command = [xlearn_predict, test_set, model, '--sigmoid']\n",
    "    return ' '.join(command)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## With count features\n",
    "- device_ip, device_id, user\n",
    "- hourly user\n",
    "\n",
    "Stats:\n",
    "- 'mid', categorical_features = ['banner_pos', 'platform_id', 'platform_domain', 'platform_category', 'user', 'device_conn_type', 'C14','C17','C20','C21', 'user_count', 'hourly_user_count'].\n",
    "    Encoding train_site does not fit in memory (spills about 500M to swap), but still gets the job done fairly quickly (03m30s).\n",
    "    Validation score: site=0.449114, app=0.340423.\n",
    "    Private 0.4941647, Public 0.4959489. (overfit!)\n",
    "\n",
    "- 'small', categorical_features = ['banner_pos', 'platform_id', 'platform_domain', 'platform_category', 'user', 'device_conn_type', 'C14','C17','C20','C21', 'user_count', 'hourly_user_count'].\n",
    "    Validation score: site=0.449503, app=0.343099, \n",
    "- 'small': with device_* cols. 01m45s for site (spilled a tiny bit--a few MB--to swap), 01m for app.\n",
    "    Validation scores: site=0.447193, app=0.340356 (weighted average = 0.3979).\n",
    "    Private 0.3974360, Public 0.3993231.\n",
    "- 'small': Without device_* cols. 01s with fast=True to prepare train sets (only about 300M memory consumption). 04m25s if fast=False.\n",
    "    01m20s for test_site, 50s for test_app, also fast=True. Memory consumption not an issue.\n",
    "- 'small', with device_* cols. 01m24s for train.\n",
    "- 'small'. site: (lr, reg) =  (0.0725, 0.0000213), app: (0.149, 0.0000151) Private 0.3983551, Public 0.4003566\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3979086003021062"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = 48252\n",
    "s = 56347\n",
    "0.447193 * (s/(a+s)) + 0.340356 * (a/(a+s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "categorical_features = ['banner_pos', 'platform_id', 'platform_domain', 'platform_category',\n",
    "                    'user', 'device_conn_type', 'C14','C17','C20','C21',\n",
    "                       #'device_id_count', 'device_ip_count', \n",
    "                        'user_count', 'hourly_user_count']\n",
    "#  add device_id, device_ip, and device_model.\n",
    "# categorical_features = ['banner_pos', 'platform_id', 'platform_domain', 'platform_category',\n",
    "#                        'device_id', 'device_ip', 'device_model',\n",
    "#                    'user', 'device_conn_type', 'C14','C17','C20','C21',\n",
    "#                        #'device_id_count', 'device_ip_count', \n",
    "#                         'user_count']\n",
    "\n",
    "train_size='mid'\n",
    "\n",
    "df = pd.read_csv(f'./data/train_{train_size}.csv')\n",
    "df.hour = pd.to_datetime(df.hour, format=\"%y%m%d%H\")\n",
    "df = create_user(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_count_col(df, cols, new_col_name):\n",
    "    counts = df.groupby(cols).size().to_frame(new_col_name)\n",
    "    df = pd.merge(df, counts, how='left', on=cols)\n",
    "    df = df.fillna({new_col_name: 0})\n",
    "    return df, counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def merge_counts(df, counts, col, count_col):\n",
    "    df = pd.merge(df, counts, how='left', on=col)\n",
    "    df[count_col] = df[count_col].fillna(0).astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df, df_device_ip_count = add_count_col(df, 'device_ip', 'device_ip_count')\n",
    "df, df_device_id_count = add_count_col(df, 'device_id', 'device_id_count')\n",
    "# bucket user count features by 5\n",
    "bucket_size = 5\n",
    "df, df_user_count = add_count_col(df, 'user', 'user_count')\n",
    "df.user_count = (df.user_count/bucket_size + 1).astype(int)\n",
    "df, df_hourly_user_count = add_count_col(df, ['user', 'hour'], 'hourly_user_count')\n",
    "df.hourly_user_count = (df.hourly_user_count/bucket_size + 1).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>hourly_user_count</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>user</th>\n",
       "      <th>hour</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">00001237</th>\n",
       "      <th>2014-10-22 17:00:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-10-22 18:00:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"2\" valign=\"top\">00001b40_ecb851b2</th>\n",
       "      <th>2014-10-25 13:00:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-10-25 15:00:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00001b40_fce66524</th>\n",
       "      <th>2014-10-24 18:00:00</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       hourly_user_count\n",
       "user              hour                                  \n",
       "00001237          2014-10-22 17:00:00                  1\n",
       "                  2014-10-22 18:00:00                  1\n",
       "00001b40_ecb851b2 2014-10-25 13:00:00                  1\n",
       "                  2014-10-25 15:00:00                  1\n",
       "00001b40_fce66524 2014-10-24 18:00:00                  1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hourly_user_count.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.user_count[df.user_count < 25].hist()\n",
    "#df.hourly_user_count[df.hourly_user_count < 10].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>click</th>\n",
       "      <th>hour</th>\n",
       "      <th>C1</th>\n",
       "      <th>banner_pos</th>\n",
       "      <th>site_id</th>\n",
       "      <th>site_domain</th>\n",
       "      <th>site_category</th>\n",
       "      <th>app_id</th>\n",
       "      <th>app_domain</th>\n",
       "      <th>...</th>\n",
       "      <th>C18</th>\n",
       "      <th>C19</th>\n",
       "      <th>C20</th>\n",
       "      <th>C21</th>\n",
       "      <th>device_ip_model</th>\n",
       "      <th>user</th>\n",
       "      <th>device_ip_count</th>\n",
       "      <th>device_id_count</th>\n",
       "      <th>user_count</th>\n",
       "      <th>hourly_user_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5173888989705882679</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-28 16:00:00</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>e151e245</td>\n",
       "      <td>7e091613</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>100148</td>\n",
       "      <td>23</td>\n",
       "      <td>805c031d_cdf6ea96</td>\n",
       "      <td>805c031d_cdf6ea96</td>\n",
       "      <td>1</td>\n",
       "      <td>3300255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>17771628550993694736</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-23 04:00:00</td>\n",
       "      <td>1005</td>\n",
       "      <td>1</td>\n",
       "      <td>e151e245</td>\n",
       "      <td>7e091613</td>\n",
       "      <td>f028772b</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "      <td>-1</td>\n",
       "      <td>13</td>\n",
       "      <td>3505e89d_158e4944</td>\n",
       "      <td>3505e89d_158e4944</td>\n",
       "      <td>1</td>\n",
       "      <td>3300255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>12217834756060365949</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-23 10:00:00</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>85f751fd</td>\n",
       "      <td>c4e18dd6</td>\n",
       "      <td>50e219e0</td>\n",
       "      <td>98fed791</td>\n",
       "      <td>d9b5648e</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>47</td>\n",
       "      <td>100182</td>\n",
       "      <td>42</td>\n",
       "      <td>6bac7859_a4b6f65b</td>\n",
       "      <td>6bac7859_a4b6f65b</td>\n",
       "      <td>6</td>\n",
       "      <td>3300255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1286618527776895333</td>\n",
       "      <td>0</td>\n",
       "      <td>2014-10-21 04:00:00</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>ac696ed4</td>\n",
       "      <td>c7dcd9d1</td>\n",
       "      <td>f66779e6</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>35</td>\n",
       "      <td>100195</td>\n",
       "      <td>43</td>\n",
       "      <td>4d6cf303_1a7697fd</td>\n",
       "      <td>4d6cf303_1a7697fd</td>\n",
       "      <td>3</td>\n",
       "      <td>3300255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7444084373938169186</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-10-25 05:00:00</td>\n",
       "      <td>1005</td>\n",
       "      <td>0</td>\n",
       "      <td>1fbe01fe</td>\n",
       "      <td>f3845767</td>\n",
       "      <td>28905ebd</td>\n",
       "      <td>ecad2386</td>\n",
       "      <td>7801e8d9</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>35</td>\n",
       "      <td>100084</td>\n",
       "      <td>79</td>\n",
       "      <td>b4809b53_94a6ac23</td>\n",
       "      <td>b4809b53_94a6ac23</td>\n",
       "      <td>19</td>\n",
       "      <td>3300255</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     id  click                hour    C1  banner_pos  \\\n",
       "0   5173888989705882679      0 2014-10-28 16:00:00  1005           1   \n",
       "1  17771628550993694736      0 2014-10-23 04:00:00  1005           1   \n",
       "2  12217834756060365949      0 2014-10-23 10:00:00  1005           0   \n",
       "3   1286618527776895333      0 2014-10-21 04:00:00  1005           0   \n",
       "4   7444084373938169186      1 2014-10-25 05:00:00  1005           0   \n",
       "\n",
       "    site_id site_domain site_category    app_id app_domain        ...          \\\n",
       "0  e151e245    7e091613      f028772b  ecad2386   7801e8d9        ...           \n",
       "1  e151e245    7e091613      f028772b  ecad2386   7801e8d9        ...           \n",
       "2  85f751fd    c4e18dd6      50e219e0  98fed791   d9b5648e        ...           \n",
       "3  ac696ed4    c7dcd9d1      f66779e6  ecad2386   7801e8d9        ...           \n",
       "4  1fbe01fe    f3845767      28905ebd  ecad2386   7801e8d9        ...           \n",
       "\n",
       "  C18 C19     C20 C21    device_ip_model               user  device_ip_count  \\\n",
       "0   2  35  100148  23  805c031d_cdf6ea96  805c031d_cdf6ea96                1   \n",
       "1   2  35      -1  13  3505e89d_158e4944  3505e89d_158e4944                1   \n",
       "2   3  47  100182  42  6bac7859_a4b6f65b  6bac7859_a4b6f65b                6   \n",
       "3   3  35  100195  43  4d6cf303_1a7697fd  4d6cf303_1a7697fd                3   \n",
       "4   0  35  100084  79  b4809b53_94a6ac23  b4809b53_94a6ac23               19   \n",
       "\n",
       "   device_id_count  user_count  hourly_user_count  \n",
       "0          3300255           1                  1  \n",
       "1          3300255           1                  1  \n",
       "2          3300255           1                  1  \n",
       "3          3300255           1                  1  \n",
       "4          3300255           1                  1  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ffm-data/train_site_mid.ffm\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atkm/code/avazu-ctr/tools/ffm_tools.py:49: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[c] = df[c].map(replace_dict).fillna(feature_dict_size).astype(int)\n",
      "/home/atkm/code/avazu-ctr/tools/ffm_tools.py:108: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df[col] = f'{i}:' + df[col].astype('str') + ':1'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./ffm-data/validate_site_mid.ffm\n",
      "./ffm-data/train_app_mid.ffm\n",
      "./ffm-data/validate_app_mid.ffm\n",
      "CPU times: user 3min 5s, sys: 7.68 s, total: 3min 13s\n",
      "Wall time: 3min 14s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# we don't use train_site/app, validate_site/app\n",
    "fast=True\n",
    "_, _, feature_dict_site, _, _, feature_dict_app = make_train_validate_data(df, categorical_features, train_size, fast=fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "del df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "exceptions must derive from BaseException",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-3323c5a13ec0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mraise\u001b[0m \u001b[0;34m\"Tune hyper-parameters.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: exceptions must derive from BaseException"
     ]
    }
   ],
   "source": [
    "raise \"Tune hyper-parameters.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_set = f'./ffm-data/train_site_{train_size}.ffm'\n",
    "validation_set = f'./ffm-data/validate_site_{train_size}.ffm'\n",
    "\n",
    "#(lr, reg) = (0.0725, 0.0000213) # w/o device_* cols\n",
    "#(lr, reg) = (0.105, 0.00000130) # w/o device_* cols\n",
    "#(lr, reg) = (0.137, 0.00000779) # w/ device_* cols\n",
    "(lr, reg) = (0.290, 0.0000205) # w/ hourly_user_count, w/o device cols\n",
    "run_training_site = xlearn_train_command(train_set, validation_set, learning_rate=lr, reg_param=reg)\n",
    "print(run_training_site)\n",
    "result = subprocess.run(run_training_site, stdout=subprocess.PIPE, shell=True)\n",
    "result.stdout.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = f'./ffm-data/train_app_{train_size}.ffm'\n",
    "validation_set = f'./ffm-data/validate_app_{train_size}.ffm'\n",
    "#(lr, reg) = (0.149, 0.0000151) # w/o device_* cols\n",
    "#(lr, reg) = (0.384, 0.0000921) # w/o device_* cols\n",
    "#(lr, reg) = (0.165, 0.00006) # w/ device_* cols\n",
    "(lr, reg) = (0.552, 0.000103) # w/ hourly_user_count, w/o device cols\n",
    "\n",
    "run_training_app = xlearn_train_command(train_set, validation_set, learning_rate=lr, reg_param=reg)\n",
    "print(run_training_app)\n",
    "result = subprocess.run(run_training_app, stdout=subprocess.PIPE, shell=True)\n",
    "result.stdout.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2858160, 26), (1719304, 26))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_size='full'\n",
    "\n",
    "if test_size == 'full':\n",
    "    df_test = pd.read_csv(f'./data/test.csv', dtype={'id': 'uint64'})\n",
    "else:\n",
    "    df_test = pd.read_csv(f'./data/test_{test_size}.csv', dtype={'id': 'uint64'})\n",
    "\n",
    "df_test.hour = pd.to_datetime(df_test.hour, format=\"%y%m%d%H\")\n",
    "df_test = create_user(df_test)\n",
    "df_test = merge_counts(df_test, df_device_ip_count, 'device_ip', 'device_ip_count')\n",
    "df_test = merge_counts(df_test, df_device_id_count, 'device_id', 'device_id_count')\n",
    "df_test = merge_counts(df_test, df_user_count, 'user', 'user_count')\n",
    "df_test = merge_counts(df_test, df_hourly_user_count, ['user', 'hour'], 'hourly_user_count')\n",
    "\n",
    "df_test_site, df_test_app = site_app_split(df_test)\n",
    "del df_test\n",
    "df_test_site.shape, df_test_app.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atkm/code/avazu-ctr/tools/ffm_tools.py:110: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['dummy'] = np.ones(len(df))\n",
      "/home/atkm/code/avazu-ctr/tools/ffm_tools.py:111: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  df['dummy'] = df['dummy'].astype(int)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 25s, sys: 4.44 s, total: 1min 29s\n",
      "Wall time: 1min 30s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ffm_data_test_site = f'./ffm-data/test_site_{test_size}.ffm'\n",
    "    \n",
    "fast=True\n",
    "df_to_ffm(df_test_site, categorical_features, \n",
    "          ffm_data_test_site, 'test', feature_dict_site, fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 51.2 s, sys: 2.58 s, total: 53.8 s\n",
      "Wall time: 54 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "ffm_data_test_app = f'./ffm-data/test_app_{test_size}.ffm'\n",
    "\n",
    "df_to_ffm(df_test_app, categorical_features, \n",
    "          ffm_data_test_app, 'test', feature_dict_app, fast)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise \"Go to Part 2: Prediction below\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Expedite data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_size='tiny'\n",
    "\n",
    "categorical_features = ['banner_pos', 'platform_id', 'platform_domain', 'platform_category',\n",
    "                    'user', 'device_conn_type', 'C14','C17','C20','C21']\n",
    "\n",
    "\n",
    "df = pd.read_csv(f'./data/train_{train_size}.csv')\n",
    "df.hour = pd.to_datetime(df.hour, format=\"%y%m%d%H\")\n",
    "df = create_user(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.cv_tools import train_test_split\n",
    "\n",
    "test_day = 30\n",
    "df_train, df_validate = train_test_split(df, None, test_day)\n",
    "df_train_site, df_train_app = site_app_split(df_train)\n",
    "df_validate_site, df_validate_app = site_app_split(df_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.ffm_tools import df_to_ffm\n",
    "\n",
    "df_to_ffm(df_validate_site, categorical_features, 'test-write.csv', 'validate', feature_dict_site, fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tools.ffm_tools import make_feature_dict, encode_features\n",
    "\n",
    "feature_dict_site = make_feature_dict(df_train_site, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = encode_features(df_train_site, feature_dict_site, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validate_encoded = encode_features(df_validate_site[categorical_features], feature_dict_site, categorical_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_dict_site.__missing__ = lambda : 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "d = {'seen': 0}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.__missing__ = lambda : 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({'c': ['unseen']}).c.map(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validate_encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoded[categorical_features ].isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded = encoded[categorical_features + ['click']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "encoded.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copied = encoded.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copied.banner_pos = '0:' + copied.banner_pos.astype('str') + ':1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, c in enumerate(copied):\n",
    "    copied[c] = f'{i}:' + copied[c].astype('str') + ':1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "copied.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copied.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded.info(memory_usage='deep')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "copied.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "copied.to_csv('test-write-encoded.csv', sep=' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "from tools.ffm_tools import ffm_row_generator\n",
    "with open('test-write-encoded.ffm', 'w') as f:\n",
    "    for ffm_row in ffm_row_generator(encoded):\n",
    "        f.write(ffm_row)\n",
    "        f.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Without count features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 0: prepare train data.\n",
    "\n",
    "Run `~/code/xlearn/build/xlearn_train ./ffm-data/train_{site,app}_{train_size}.ffm -s 2 -v ./ffm-data/validate_{site,app}_{train_size}.ffm`.\n",
    "\n",
    "Generates `./ffm-data/train_{site,app}_{train_size}.ffm.model`.\n",
    "\n",
    "Early-stopping is enabled by default when a validation set is provided.\n",
    "\n",
    "Stats:\n",
    "- 'small', with categorical_features = ['banner_pos', 'platform_id', 'platform_domain', 'platform_category', 'user', 'device_conn_type', 'C14','C17','C20','C21'] => 04m25s (with the new ffm_row_generator).\n",
    "\n",
    "    Use (lr, reg) = (1.5055668655636434, 0.14551999446480063) for site; (0.00166189386987065, 0.48305136367563084) for app.\n",
    "    Private=0.4278890, Public=0.4292961\n",
    "    \n",
    "    Use site: (lr, reg) =  (0.062, 0.00000561), app: (0.433, 0.000104).\n",
    "    Private=0.3977579, Public=0.3997753\n",
    "    \n",
    "- 'small', with categorical_features = ['banner_pos', 'platform_id', 'platform_domain', 'platform_category',\n",
    "    'device_id', 'device_ip', 'device_model',\n",
    "    'user', 'device_conn_type', 'C14','C17','C20','C21'] => 09m15s, best losses: site-0.447526, app-0.343323."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "categorical_features = ['banner_pos', 'platform_id', 'platform_domain', 'platform_category',\n",
    "                    'user', 'device_conn_type', 'C14','C17','C20','C21']\n",
    "#  add device_id, device_ip, and device_model.\n",
    "#categorical_features = ['banner_pos', 'platform_id', 'platform_domain', 'platform_category',\n",
    "#                        'device_id', 'device_ip', 'device_model',\n",
    "#                    'user', 'device_conn_type', 'C14','C17','C20','C21']\n",
    "\n",
    "train_size='small'\n",
    "\n",
    "df = pd.read_csv(f'./data/train_{train_size}.csv')\n",
    "df.hour = pd.to_datetime(df.hour, format=\"%y%m%d%H\")\n",
    "df = create_user(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%%time\n",
    "# we don't use train_site/app, validate_site/app\n",
    "_, _, feature_dict_site, _, _, feature_dict_app = make_train_validate_data(df, categorical_features, train_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise \"Tune Model\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = f'./ffm-data/train_site_{train_size}.ffm'\n",
    "validation_set = f'./ffm-data/validate_site_{train_size}.ffm'\n",
    "\n",
    "(lr, reg) = (0.062, 0.00000561)\n",
    "run_training_site = xlearn_train_command(train_set, validation_set, learning_rate=lr, reg_param=reg)\n",
    "run_training_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = subprocess.run(run_training_site, stdout=subprocess.PIPE, shell=True)\n",
    "result.stdout.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_set = f'./ffm-data/train_app_{train_size}.ffm'\n",
    "validation_set = f'./ffm-data/validate_app_{train_size}.ffm'\n",
    "(lr, reg) = (0.433, 0.000104)\n",
    "\n",
    "run_training_app = xlearn_train_command(train_set, validation_set, learning_rate=lr, reg_param=reg)\n",
    "run_training_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = subprocess.run(run_training_app, stdout=subprocess.PIPE, shell=True)\n",
    "result.stdout.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise \"Train/tune models.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1: prepare test data.\n",
    "\n",
    "Generates `./ffm-data/test_{site,app}_{test_size}.ffm.out`.\n",
    "\n",
    "Stats:\n",
    "- 'full', with categorical_features = ['banner_pos', 'platform_id', 'platform_domain', 'platform_category', 'user', 'device_conn_type', 'C14','C17','C20','C21']  --> site = 08m42s (old 27m); app = 05m19s (old 14m).\n",
    "- 'small', with categorical_features = ['banner_pos', 'platform_id', 'platform_domain', 'platform_category', 'user', 'device_conn_type', 'C14','C17','C20','C21']  --> site = 01m53s (old 06m); app = 01m09s (old 4m).\n",
    "- 'full', with categorical_features = ['banner_pos', 'platform_id', 'platform_domain', 'platform_category',\n",
    "    'device_id', 'device_ip', 'device_model',\n",
    "    'user', 'device_conn_type', 'C14','C17','C20','C21'] => site = 25m39s; app = 15m45s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_size='tiny'\n",
    "\n",
    "if test_size == 'full':\n",
    "    df_test = pd.read_csv(f'./data/test.csv', dtype={'id': 'uint64'})\n",
    "else:\n",
    "    df_test = pd.read_csv(f'./data/test_{test_size}.csv', dtype={'id': 'uint64'})\n",
    "df_test = create_user(df_test)\n",
    "\n",
    "df_test_site, df_test_app = site_app_split(df_test)\n",
    "del df_test\n",
    "df_test_site.shape, df_test_app.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ffm_data_test_site = f'./ffm-data/test_site_{test_size}.ffm'\n",
    "    \n",
    "df_to_ffm(df_test_site, categorical_features, \n",
    "          ffm_data_test_site, 'test', feature_dict_site, fast=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "ffm_data_test_app = f'./ffm-data/test_app_{test_size}.ffm'\n",
    "\n",
    "df_to_ffm(df_test_app, categorical_features, \n",
    "          ffm_data_test_app, 'test', feature_dict_app)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2: predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'~/code/xlearn/build/xlearn_predict ./ffm-data/test_site_full.ffm ./ffm-data/train_site_mid.ffm.model --sigmoid'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = f'./ffm-data/test_site_{test_size}.ffm'\n",
    "model = f'./ffm-data/train_site_{train_size}.ffm.model'\n",
    "run_predict_site = xlearn_predict_command(test_set, model)\n",
    "run_predict_site"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\x1b[32m\\x1b[1m----------------------------------------------------------------------------------------------\\n           _\\n          | |\\n     __  _| |     ___  __ _ _ __ _ __\\n     \\\\ \\\\/ / |    / _ \\\\/ _` | '__| '_ \\\\ \\n      >  <| |___|  __/ (_| | |  | | | |\\n     /_/\\\\_\\\\_____/\\\\___|\\\\__,_|_|  |_| |_|\\n\\n        xLearn   -- 0.35 Version --\\n----------------------------------------------------------------------------------------------\\n\\n\\x1b[39m\\x1b[0m\\x1b[32m\\x1b[1m[ ACTION     ] Load model ...\\x1b[0m\\n\\x1b[32m[------------] \\x1b[0mLoad model from ./ffm-data/train_site_mid.ffm.model\\n\\x1b[32m[------------] \\x1b[0mLoss function: cross-entropy\\n\\x1b[32m[------------] \\x1b[0mScore function: ffm\\n\\x1b[32m[------------] \\x1b[0mNumber of Feature: 1505173\\n\\x1b[32m[------------] \\x1b[0mNumber of K: 4\\n\\x1b[32m[------------] \\x1b[0mNumber of field: 12\\n\\x1b[32m[------------] \\x1b[0mTime cost for loading model: 1.19 (sec)\\n\\x1b[32m\\x1b[1m[ ACTION     ] Read Problem ...\\x1b[0m\\n\\x1b[32m[------------] \\x1b[0mFirst check if the text file has been already converted to binary format.\\n\\x1b[32m[------------] \\x1b[0mBinary file (./ffm-data/test_site_full.ffm.bin) NOT found. Convert text file to binary file.\\n\\x1b[32m[------------] \\x1b[0mTime cost for reading problem: 9.77 (sec)\\n\\x1b[32m\\x1b[1m[ ACTION     ] Start to predict ...\\x1b[0m\\n\\x1b[32m[------------] \\x1b[0mThe test loss is: 1.777174\\n\\x1b[32m\\x1b[1m[ ACTION     ] Clear the xLearn environment ...\\x1b[0m\\n\\x1b[32m[------------] \\x1b[0mTotal time cost: 12.84 (sec)\\n\""
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = subprocess.run(run_predict_site, stdout=subprocess.PIPE, shell=True)\n",
    "result.stdout.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'~/code/xlearn/build/xlearn_predict ./ffm-data/test_app_full.ffm ./ffm-data/train_app_mid.ffm.model --sigmoid'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_set = f'./ffm-data/test_app_{test_size}.ffm'\n",
    "model = f'./ffm-data/train_app_{train_size}.ffm.model'\n",
    "run_predict_app = xlearn_predict_command(test_set, model)\n",
    "run_predict_app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\x1b[32m\\x1b[1m----------------------------------------------------------------------------------------------\\n           _\\n          | |\\n     __  _| |     ___  __ _ _ __ _ __\\n     \\\\ \\\\/ / |    / _ \\\\/ _` | '__| '_ \\\\ \\n      >  <| |___|  __/ (_| | |  | | | |\\n     /_/\\\\_\\\\_____/\\\\___|\\\\__,_|_|  |_| |_|\\n\\n        xLearn   -- 0.35 Version --\\n----------------------------------------------------------------------------------------------\\n\\n\\x1b[39m\\x1b[0m\\x1b[32m\\x1b[1m[ ACTION     ] Load model ...\\x1b[0m\\n\\x1b[32m[------------] \\x1b[0mLoad model from ./ffm-data/train_app_mid.ffm.model\\n\\x1b[32m[------------] \\x1b[0mLoss function: cross-entropy\\n\\x1b[32m[------------] \\x1b[0mScore function: ffm\\n\\x1b[32m[------------] \\x1b[0mNumber of Feature: 740329\\n\\x1b[32m[------------] \\x1b[0mNumber of K: 4\\n\\x1b[32m[------------] \\x1b[0mNumber of field: 12\\n\\x1b[32m[------------] \\x1b[0mTime cost for loading model: 0.58 (sec)\\n\\x1b[32m\\x1b[1m[ ACTION     ] Read Problem ...\\x1b[0m\\n\\x1b[32m[------------] \\x1b[0mFirst check if the text file has been already converted to binary format.\\n\\x1b[32m[------------] \\x1b[0mBinary file (./ffm-data/test_app_full.ffm.bin) NOT found. Convert text file to binary file.\\n\\x1b[32m[------------] \\x1b[0mTime cost for reading problem: 5.60 (sec)\\n\\x1b[32m\\x1b[1m[ ACTION     ] Start to predict ...\\x1b[0m\\n\\x1b[32m[------------] \\x1b[0mThe test loss is: 2.311275\\n\\x1b[32m\\x1b[1m[ ACTION     ] Clear the xLearn environment ...\\x1b[0m\\n\\x1b[32m[------------] \\x1b[0mTotal time cost: 7.27 (sec)\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = subprocess.run(run_predict_app, stdout=subprocess.PIPE, shell=True)\n",
    "result.stdout.decode()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raise \"run prediction\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3: write submission.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_site = f'./ffm-data/test_site_{test_size}.ffm'\n",
    "prediction_site_out = prediction_site + '.out'\n",
    "prediction_site_id = prediction_site + '.id'\n",
    "prediction_app = f'./ffm-data/test_app_{test_size}.ffm'\n",
    "prediction_app_out = prediction_app + '.out'\n",
    "prediction_app_id = prediction_app + '.id'\n",
    "\n",
    "write_submission(prediction_site_out, prediction_site_id, prediction_app_out, prediction_app_id, 'submission-.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 (obsolete): train model and predict.\n",
    "Do this in shell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_ffm(train_set, validate_set, test_set, model_out, predict_out):\n",
    "    ffm_model = xl.create_ffm()\n",
    "    ffm_model.setTrain(train_set)\n",
    "    ffm_model.setValidate(validate_set)\n",
    "    \n",
    "    param = {'task':'binary', 'lr':0.2, 'lambda':0.002}\n",
    "    ffm_model.fit(param, model_out)\n",
    "    \n",
    "    ffm_model.setSigmoid()\n",
    "    ffm_model.setTest(test_set)\n",
    "    ffm_model.predict(model_out, predict_out)\n",
    "    print(f'Prediction written to {predict_out}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO: move this to tools/kaggle_tools\n",
    "def validate_submission(submission_csv, ids):\n",
    "    \"\"\"\n",
    "    Ensure that the submission file is in the right format, \n",
    "    and that it contains required id's.\n",
    "    \"\"\"\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = 'small'\n",
    "test_size = 'small'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_site = f'./ffm-data/train_site_{train_size}.ffm'\n",
    "validate_site = f'./ffm-data/validate_site_{train_size}.ffm'\n",
    "test_site = f'./ffm-data/test_site_{test_size}.ffm'\n",
    "model_site_out = './xlearn-out/ffm-site.out'\n",
    "predict_site_out = './xlearn-out/out-site.txt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# TODO: kernel dies when the test \n",
    "run_ffm(train_site, validate_site, test_site, model_site_out, predict_site_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_app = f'./ffm-data/train_app_{train_size}.ffm'\n",
    "validate_app = f'./ffm-data/validate_app_{train_size}.ffm'\n",
    "test_app = f'./ffm-data/test_app_{test_size}.ffm'\n",
    "model_app_out = './xlearn-out/ffm-app.out'\n",
    "predict_app_out = './xlearn-out/out-app.txt'\n",
    "\n",
    "run_ffm(train_app, validate_app, test_app, model_app_out, predict_app_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_id_site = f'./ffm-data/test_site_{test_size}.ffm.id'\n",
    "prediction_id_app = f'./ffm-data/test_app_{test_size}.ffm.id'\n",
    "write_submission(predict_site_out, prediction_id_site, predict_app_out, prediction_id_app, 'submission-.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
